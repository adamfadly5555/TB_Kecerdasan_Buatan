# -*- coding: utf-8 -*-
"""TB_Kecerdasan_Buatan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G4yjMKWXXuhmUwIR-bbkRyi4yWp19G5n
"""

from google.colab import drive
drive.mount('/content/drive')

dataset_path = "/content/drive/MyDrive/DATASET/predic_tabel.csv"

import pandas as pd

df = pd.read_csv(dataset_path)

# Ukuran data
print("Shape:", df.shape)

# Informasi kolom
df.info()

# Statistik deskriptif
df.describe()

# Ukuran data
print("Shape:", df.shape)

# Informasi kolom
df.info()

# Statistik deskriptif
df.describe()

print(df.dtypes)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='Merokok', data=df)
plt.title('Distribusi Status Merokok')
plt.xlabel('Status Merokok')
plt.ylabel('Jumlah')
plt.show()

print(df.columns)

import matplotlib.pyplot as plt
import seaborn as sns

# Visualisasi distribusi fitur kategorik dari dataset
plt.figure(figsize=(12, 4))

# Barplot untuk kolom Merokok
plt.subplot(1, 3, 1)
sns.countplot(x='Merokok', data=df)
plt.title('Distribusi Merokok')

# Barplot untuk kolom Aktivitas_Begadang
plt.subplot(1, 3, 2)
sns.countplot(x='Aktivitas_Begadang', data=df)
plt.title('Distribusi Begadang')

# Barplot untuk kolom Hasil
plt.subplot(1, 3, 3)
sns.countplot(x='Hasil', data=df)
plt.title('Distribusi Hasil')

plt.tight_layout()
plt.show()

print(df['Hasil'].value_counts(normalize=True))

import pandas as pd

print(pd.crosstab(df['Merokok'], df['Hasil'], normalize='index'))

print(pd.crosstab(df['Usia'], df['Hasil'], normalize='index'))

print(df.isnull().sum())

print(df.duplicated().sum())

df.drop_duplicates(inplace=True)
df.dropna(inplace=True)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df_encoded = df.apply(le.fit_transform)

print(df_encoded)

from sklearn.preprocessing import StandardScaler

numerik_fitur = ['Usia', 'Aktivitas_Begadang', 'Aktivitas_Olahraga']

scaler = StandardScaler()
df_encoded[numerik_fitur] = scaler.fit_transform(df_encoded[numerik_fitur])

print("Data setelah standardisasi:")
print(df_encoded.head())

import seaborn as sns
import matplotlib.pyplot as plt


plt.figure(figsize=(10, 8))
sns.heatmap(df_encoded.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Korelasi antar fitur numerik")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split

X = df_encoded.drop('Hasil', axis=1)
y = df_encoded['Hasil']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train:\n", X_train)
print("y_train:\n", y_train)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

model = KNeighborsClassifier(n_neighbors=3)

model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

y_pred_knn = model_knn.predict(X_test)

cm = confusion_matrix(y_test, y_pred_knn)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - KNN")
plt.show()

# Prediksi data test
y_pred = model.predict(X_test)

# Evaluasi
print("Akurasi:", accuracy_score(y_test, y_pred))
print("\nKlasifikasi:\n", classification_report(y_test, y_pred))

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Reduksi dimensi ke 2 komponen
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Latih ulang model KNN di ruang PCA
knn_2d = KNeighborsClassifier(n_neighbors=3)
knn_2d.fit(X_train_pca, y_train)

# Prediksi data test di ruang PCA
y_pred_pca = knn_2d.predict(X_test_pca)

# Buat visualisasi
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_pred_pca, cmap='viridis', alpha=0.7)
plt.title("Visualisasi Klasifikasi KNN dalam 2D (PCA)")
plt.xlabel("Komponen Utama 1")
plt.ylabel("Komponen Utama 2")
legend1 = plt.legend(*scatter.legend_elements(), title="Kelas")
plt.gca().add_artist(legend1)
plt.grid(True)
plt.show()

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_knn_pred = knn.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report

print("Akurasi KNN:", accuracy_score(y_test, y_knn_pred))
print("\nKlasifikasi KNN:\n", classification_report(y_test, y_knn_pred))

from sklearn.naive_bayes import GaussianNB

nb = GaussianNB()
nb.fit(X_train, y_train)
y_nb_pred = nb.predict(X_test)

print("Akurasi Naive Bayes:", accuracy_score(y_test, y_nb_pred))
print("\nKlasifikasi Naive Bayes:\n", classification_report(y_test, y_nb_pred))

from sklearn.svm import SVC

svm = SVC()
svm.fit(X_train, y_train)
y_svm_pred = svm.predict(X_test)

print("Akurasi SVM:", accuracy_score(y_test, y_svm_pred))
print("\nKlasifikasi SVM:\n", classification_report(y_test, y_svm_pred))

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=3),
    "Naive Bayes": GaussianNB(),
    "Support Vector Machine": SVC()
}

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    acc = accuracy_score(y_test, pred)
    results.append({"Model": name, "Akurasi": round(acc, 2)})

df_results = pd.DataFrame(results)
print(df_results)